{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a3ca3449",
      "metadata": {},
      "source": [
        "# Docling Batch Processing Notebook\n",
        "\n",
        "## Overview\n",
        "\n",
        "This Jupyter notebook provides efficient batch processing of PDF documents using Docling, with hardware-aware optimizations for GPU and CPU utilization.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Python 3.x\n",
        "- NVIDIA GPU with CUDA support\n",
        "- Required Python packages:\n",
        "  ```\n",
        "  docling\n",
        "  psutil\n",
        "  pyyaml\n",
        "  ```\n",
        "- Minimum 8GB RAM recommended\n",
        "- NVIDIA drivers with `nvidia-smi` utility\n",
        "\n",
        "## Hardware Optimization\n",
        "\n",
        "The notebook automatically detects and configures:\n",
        "\n",
        "- Available GPU memory for optimal batch sizes\n",
        "- CPU core count for potential parallel processing\n",
        "- System RAM availability\n",
        "\n",
        "## Input/Output Structure\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d640af9",
      "metadata": {
        "vscode": {
          "languageId": ""
        }
      },
      "source": [
        "project/\n",
        "├── input-data/\n",
        "│ └── pdf/ # Place input PDFs here\n",
        "└── output-data/\n",
        "├── document1/ # One folder per input\n",
        "│ ├── document1.json\n",
        "│ ├── document1.html\n",
        "│ ├── document1.md\n",
        "│ └── ...\n",
        "└── document2/\n",
        "└── ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59f4f299",
      "metadata": {},
      "source": [
        "## Features\n",
        "\n",
        "- Automatic hardware detection and optimization\n",
        "- Batch processing for GPU efficiency\n",
        "- Multiple output formats:\n",
        "  - JSON (with image placeholders)\n",
        "  - HTML (with embedded images)\n",
        "  - Markdown\n",
        "  - YAML\n",
        "  - Plain text\n",
        "  - Doctags\n",
        "\n",
        "## Usage\n",
        "\n",
        "1. Place PDF files in the `input-data/pdf/` directory\n",
        "2. Run all cells in the notebook\n",
        "3. Processed files will appear in `output-data/` with one subfolder per input document\n",
        "\n",
        "## Performance Notes\n",
        "\n",
        "- GPU memory usage: ~2000MB per document\n",
        "- Batch size is automatically calculated based on available GPU memory\n",
        "- Processing multiple documents simultaneously for optimal GPU utilization\n",
        "\n",
        "## Error Handling\n",
        "\n",
        "- Failed conversions are logged but don't stop the batch\n",
        "- Partial successes are noted with specific error messages\n",
        "- Final summary shows success/partial/failure counts\n",
        "\n",
        "## Logging\n",
        "\n",
        "The notebook provides detailed logging of:\n",
        "\n",
        "- Hardware detection results\n",
        "- Conversion progress and errors\n",
        "- Final processing statistics\n",
        "- Total processing time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4a333a1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell to Import necessary libraries\n",
        "import json\n",
        "import logging\n",
        "import time\n",
        "import yaml\n",
        "import psutil\n",
        "import os\n",
        "import subprocess\n",
        "from collections.abc import Iterable\n",
        "from pathlib import Path\n",
        "from docling_core.types.doc import ImageRefMode\n",
        "from docling.backend.docling_parse_v4_backend import DoclingParseV4DocumentBackend\n",
        "from docling.datamodel.base_models import ConversionStatus, InputFormat\n",
        "from docling.datamodel.document import ConversionResult\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
        "from docling.document_converter import DocumentConverter, PdfFormatOption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6809adde",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected CPU cores: 32 | Total RAM: 62.11 GB\n",
            "Using 28 worker processes.\n",
            "Detected GPU with 24123 MB free. Suggested batch size: 12\n"
          ]
        }
      ],
      "source": [
        "# Hardware checks to determine most efficient settings\n",
        "def get_gpu_memory():\n",
        "    \"\"\"Returns total and free GPU memory in MB (NVIDIA only).\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [\"nvidia-smi\", \"--query-gpu=memory.total,memory.free\",\n",
        "                \"--format=csv,nounits,noheader\"],\n",
        "            stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True, text=True\n",
        "        )\n",
        "        total, free = map(int, result.stdout.strip().split('\\n')[0].split(','))\n",
        "        return total, free\n",
        "    except Exception as e:\n",
        "        print(\"Could not query GPU memory:\", e)\n",
        "        return None, None\n",
        "\n",
        "\n",
        "# CPU checks\n",
        "num_cores = os.cpu_count()\n",
        "mem = psutil.virtual_memory()\n",
        "\n",
        "if num_cores is None or num_cores < 2:\n",
        "    print(\"Warning: Only one CPU core detected. Parallel processing may not help.\")\n",
        "if mem.total < 8 * 1024 ** 3:  # Less than 8GB RAM\n",
        "    print(\"Warning: Low system memory detected.\")\n",
        "\n",
        "print(\n",
        "    f\"Detected CPU cores: {num_cores} | Total RAM: {mem.total / (1024 ** 3):.2f} GB\"\n",
        ")\n",
        "\n",
        "if num_cores is not None and num_cores > 8:\n",
        "    max_workers = num_cores - 4\n",
        "elif num_cores is not None and num_cores > 1:\n",
        "    max_workers = num_cores\n",
        "else:\n",
        "    max_workers = 1\n",
        "\n",
        "print(f\"Using {max_workers} worker processes.\")\n",
        "\n",
        "# GPU checks and batch size suggestion\n",
        "MEMORY_PER_DOC_MB = 2000  # Adjust for your workload\n",
        "total_mem, free_mem = get_gpu_memory()\n",
        "if free_mem:\n",
        "    max_batch_size = max(1, free_mem // MEMORY_PER_DOC_MB)\n",
        "    print(\n",
        "        f\"Detected GPU with {free_mem} MB free. Suggested batch size: {max_batch_size}\")\n",
        "else:\n",
        "    max_batch_size = 1\n",
        "    print(\"No GPU detected or unable to query. Using batch size: 1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "db86b960",
      "metadata": {},
      "outputs": [],
      "source": [
        "_log = logging.getLogger(__name__)\n",
        "\n",
        "USE_V2 = True\n",
        "USE_LEGACY = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4e051e19",
      "metadata": {},
      "outputs": [],
      "source": [
        "def export_documents(\n",
        "    conv_results: Iterable[ConversionResult],\n",
        "    output_dir: Path,\n",
        "):\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    success_count = 0\n",
        "    failure_count = 0\n",
        "    partial_success_count = 0\n",
        "\n",
        "    for conv_res in conv_results:\n",
        "        if conv_res.status == ConversionStatus.SUCCESS:\n",
        "            success_count += 1\n",
        "            doc_filename = conv_res.input.file.stem\n",
        "\n",
        "            if USE_V2:\n",
        "                conv_res.document.save_as_json(\n",
        "                    output_dir / f\"{doc_filename}.json\",\n",
        "                    image_mode=ImageRefMode.PLACEHOLDER,\n",
        "                )\n",
        "                conv_res.document.save_as_html(\n",
        "                    output_dir / f\"{doc_filename}.html\",\n",
        "                    image_mode=ImageRefMode.EMBEDDED,\n",
        "                )\n",
        "                conv_res.document.save_as_doctags(\n",
        "                    output_dir / f\"{doc_filename}.doctags.txt\"\n",
        "                )\n",
        "                conv_res.document.save_as_markdown(\n",
        "                    output_dir / f\"{doc_filename}.md\",\n",
        "                    image_mode=ImageRefMode.PLACEHOLDER,\n",
        "                )\n",
        "                conv_res.document.save_as_markdown(\n",
        "                    output_dir / f\"{doc_filename}.txt\",\n",
        "                    image_mode=ImageRefMode.PLACEHOLDER,\n",
        "                )\n",
        "\n",
        "                # Export Docling document format to YAML:\n",
        "                with (output_dir / f\"{doc_filename}.yaml\").open(\"w\") as fp:\n",
        "                    fp.write(yaml.safe_dump(\n",
        "                        conv_res.document.export_to_dict()))\n",
        "\n",
        "                # Export Docling document format to doctags:\n",
        "                with (output_dir / f\"{doc_filename}.doctags.txt\").open(\"w\") as fp:\n",
        "                    fp.write(conv_res.document.export_to_doctags())\n",
        "\n",
        "                # Export Docling document format to markdown:\n",
        "                with (output_dir / f\"{doc_filename}.md\").open(\"w\") as fp:\n",
        "                    fp.write(conv_res.document.export_to_markdown())\n",
        "\n",
        "                # Export Docling document format to text:\n",
        "                with (output_dir / f\"{doc_filename}.txt\").open(\"w\") as fp:\n",
        "                    fp.write(conv_res.document.export_to_markdown(\n",
        "                    ))\n",
        "\n",
        "            if USE_LEGACY:\n",
        "                # Export Deep Search document JSON format:\n",
        "                with (output_dir / f\"{doc_filename}.legacy.json\").open(\n",
        "                    \"w\", encoding=\"utf-8\"\n",
        "                ) as fp:\n",
        "                    fp.write(json.dumps(\n",
        "                        conv_res.document.export_to_dict()))\n",
        "\n",
        "                # Export Text format:\n",
        "                with (output_dir / f\"{doc_filename}.legacy.txt\").open(\n",
        "                    \"w\", encoding=\"utf-8\"\n",
        "                ) as fp:\n",
        "                    fp.write(\n",
        "                        conv_res.document.export_to_markdown(\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "                # Export Markdown format:\n",
        "                with (output_dir / f\"{doc_filename}.legacy.md\").open(\n",
        "                    \"w\", encoding=\"utf-8\"\n",
        "                ) as fp:\n",
        "                    fp.write(conv_res.document.export_to_markdown())\n",
        "\n",
        "                # Export Document Tags format:\n",
        "                with (output_dir / f\"{doc_filename}.legacy.doctags.txt\").open(\n",
        "                    \"w\", encoding=\"utf-8\"\n",
        "                ) as fp:\n",
        "                    fp.write(conv_res.document.export_to_doctags())\n",
        "\n",
        "        elif conv_res.status == ConversionStatus.PARTIAL_SUCCESS:\n",
        "            _log.info(\n",
        "                f\"Document {conv_res.input.file} was partially converted with the following errors:\"\n",
        "            )\n",
        "            for item in conv_res.errors:\n",
        "                _log.info(f\"\\t{item.error_message}\")\n",
        "            partial_success_count += 1\n",
        "        else:\n",
        "            _log.info(f\"Document {conv_res.input.file} failed to convert.\")\n",
        "            failure_count += 1\n",
        "\n",
        "    _log.info(\n",
        "        f\"Processed {success_count + partial_success_count + failure_count} docs, \"\n",
        "        f\"of which {failure_count} failed \"\n",
        "        f\"and {partial_success_count} were partially converted.\"\n",
        "    )\n",
        "    return success_count, partial_success_count, failure_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c51a871b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def batch(iterable, batch_size):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, batch_size):\n",
        "        yield iterable[ndx:min(ndx + batch_size, l)]\n",
        "\n",
        "\n",
        "def main():\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    try:\n",
        "        base_dir = Path(__file__).parent\n",
        "    except NameError:\n",
        "        base_dir = Path().resolve()\n",
        "\n",
        "    # Set up the input directory (change as needed)\n",
        "    input_dir = base_dir / \"input-data/pdf\"\n",
        "    # Collect all PDF files in the input directory\n",
        "    input_doc_paths = list(input_dir.glob(\"*.pdf\"))\n",
        "\n",
        "    if not input_doc_paths:\n",
        "        print(f\"No PDF files found in {input_dir}\")\n",
        "        return\n",
        "\n",
        "    pipeline_options = PdfPipelineOptions()\n",
        "    pipeline_options.generate_page_images = True\n",
        "\n",
        "    doc_converter = DocumentConverter(\n",
        "        format_options={\n",
        "            InputFormat.PDF: PdfFormatOption(\n",
        "                pipeline_options=pipeline_options, backend=DoclingParseV4DocumentBackend\n",
        "            )\n",
        "        }\n",
        "    )\n",
        "\n",
        "    output_dir = base_dir / \"output-data\"\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    total_success = 0\n",
        "    total_partial = 0\n",
        "    total_failure = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for file_batch in batch(input_doc_paths, max_batch_size):\n",
        "        conv_results = doc_converter.convert_all(\n",
        "            file_batch,\n",
        "            raises_on_error=False,\n",
        "        )\n",
        "        for conv_res in conv_results:\n",
        "            # Make a subfolder for each input document\n",
        "            doc_filename = conv_res.input.file.stem\n",
        "            doc_output_dir = output_dir / doc_filename\n",
        "            doc_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "            # Export this document's results to its subfolder\n",
        "            export_documents([conv_res], output_dir=doc_output_dir)\n",
        "            if conv_res.status == ConversionStatus.SUCCESS:\n",
        "                total_success += 1\n",
        "            elif conv_res.status == ConversionStatus.PARTIAL_SUCCESS:\n",
        "                total_partial += 1\n",
        "            else:\n",
        "                total_failure += 1\n",
        "\n",
        "        success_count, partial_success_count, failure_count = export_documents(\n",
        "            conv_results, output_dir=output_dir,\n",
        "        )\n",
        "        total_success += success_count\n",
        "        total_partial += partial_success_count\n",
        "        total_failure += failure_count\n",
        "\n",
        "    end_time = time.time() - start_time\n",
        "\n",
        "    _log.info(f\"Document conversion complete in {end_time:.2f} seconds.\")\n",
        "    print(\n",
        "        f\"Total: {total_success} success, {total_partial} partial, {total_failure} failed.\")\n",
        "\n",
        "    if total_failure > 0:\n",
        "        raise RuntimeError(\n",
        "            f\"The example failed converting {total_failure} on {len(input_doc_paths)}.\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0a2776c0",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:docling.document_converter:Going to convert document batch...\n",
            "INFO:docling.document_converter:Initializing pipeline for StandardPdfPipeline with options hash 656085771f8cc0529fb7a68ab9f77b00\n",
            "INFO:docling.models.factories.base_factory:Loading plugin 'docling_defaults'\n",
            "INFO:docling.models.factories:Registered ocr engines: ['easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
            "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
            "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
            "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
            "INFO:docling.models.factories.base_factory:Loading plugin 'docling_defaults'\n",
            "INFO:docling.models.factories:Registered picture descriptions: ['vlm', 'api']\n",
            "INFO:docling.pipeline.base_pipeline:Processing document Wildspire_ Heroes and Animal Companions Character Booklet_v1.pdf\n",
            "INFO:docling.document_converter:Finished converting document Wildspire_ Heroes and Animal Companions Character Booklet_v1.pdf in 80.36 sec.\n",
            "INFO:__main__:Processed 1 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:docling.pipeline.base_pipeline:Processing document DnD-red-dragons-tale.pdf\n",
            "INFO:docling.document_converter:Finished converting document DnD-red-dragons-tale.pdf in 32.31 sec.\n",
            "INFO:__main__:Processed 1 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:docling.document_converter:Going to convert document batch...\n",
            "INFO:docling.pipeline.base_pipeline:Processing document Side_Quest_4_Pack_4_of_4_Drink_From_the_Goblet_.pdf\n",
            "INFO:docling.document_converter:Finished converting document Side_Quest_4_Pack_4_of_4_Drink_From_the_Goblet_.pdf in 5.37 sec.\n",
            "INFO:__main__:Processed 1 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:docling.pipeline.base_pipeline:Processing document Side_Quest_4_Pack_1_of_4_Dwarfs.pdf\n",
            "INFO:docling.document_converter:Finished converting document Side_Quest_4_Pack_1_of_4_Dwarfs.pdf in 5.69 sec.\n",
            "INFO:__main__:Processed 1 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:docling.document_converter:Going to convert document batch...\n",
            "INFO:docling.pipeline.base_pipeline:Processing document (Start Here! Heroes of Sol'an_v1.pdf\n",
            "INFO:docling.document_converter:Finished converting document (Start Here! Heroes of Sol'an_v1.pdf in 178.82 sec.\n",
            "INFO:__main__:Processed 1 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:docling.pipeline.base_pipeline:Processing document 2. Sol'an Campaign Booklet_Greenhill_(Lvl 4-7).pdf\n",
            "INFO:docling.document_converter:Finished converting document 2. Sol'an Campaign Booklet_Greenhill_(Lvl 4-7).pdf in 165.13 sec.\n",
            "INFO:__main__:Processed 1 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:docling.document_converter:Going to convert document batch...\n",
            "INFO:docling.pipeline.base_pipeline:Processing document Heroes of Sol'an - Player's Guide_r1.pdf\n",
            "INFO:docling.document_converter:Finished converting document Heroes of Sol'an - Player's Guide_r1.pdf in 61.86 sec.\n",
            "INFO:__main__:Processed 1 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:docling.pipeline.base_pipeline:Processing document 2d-terrain-beginners_guide.pdf\n",
            "INFO:docling.document_converter:Finished converting document 2d-terrain-beginners_guide.pdf in 15.65 sec.\n",
            "INFO:__main__:Processed 1 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:docling.document_converter:Going to convert document batch...\n",
            "INFO:docling.pipeline.base_pipeline:Processing document Side_Quests_4_Pack_2__3_Stone_Carved_Runes_and_A_Quick_Contest_.pdf\n",
            "INFO:docling.document_converter:Finished converting document Side_Quests_4_Pack_2__3_Stone_Carved_Runes_and_A_Quick_Contest_.pdf in 6.61 sec.\n",
            "INFO:__main__:Processed 1 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:docling.pipeline.base_pipeline:Processing document The Lost Crypts of the Gargoyle Baroness 01.pdf\n",
            "INFO:docling.document_converter:Finished converting document The Lost Crypts of the Gargoyle Baroness 01.pdf in 7.09 sec.\n",
            "INFO:__main__:Processed 1 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:docling.document_converter:Going to convert document batch...\n",
            "INFO:docling.pipeline.base_pipeline:Processing document 1. Sol'an Campaign Booklet_Boiler Bay_(Lvl 1-4).pdf\n",
            "INFO:docling.document_converter:Finished converting document 1. Sol'an Campaign Booklet_Boiler Bay_(Lvl 1-4).pdf in 154.71 sec.\n",
            "INFO:__main__:Processed 1 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:docling.pipeline.base_pipeline:Processing document 3. Sol'an Campaign Booklet_Gorespire Keep_(Lvls 7-10) (1).pdf\n",
            "INFO:docling.document_converter:Finished converting document 3. Sol'an Campaign Booklet_Gorespire Keep_(Lvls 7-10) (1).pdf in 193.46 sec.\n",
            "INFO:__main__:Processed 1 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:__main__:Processed 0 docs, of which 0 failed and 0 were partially converted.\n",
            "INFO:__main__:Document conversion complete in 924.49 seconds.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total: 12 success, 0 partial, 0 failed.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".nbenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
